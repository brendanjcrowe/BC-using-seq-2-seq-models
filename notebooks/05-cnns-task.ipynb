{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional NNs in NumPy and PyTorch\n",
    "Notebook created by Laura Dietz for ML4Seq\n",
    "\n",
    "Tested with Python 3.7.6 on anaconda Numpy version 1.19.1 and PyTorch version 1.6.0 and 1.7.0\n",
    "\n",
    "If you find bugs in this notebook (or something that could be a bug), please let me know via Piazza (I am also awarding bounty points for big bugs). \n",
    "\n",
    "\n",
    "The goals are for you to work through the basics of convolutional neural networks, both as\n",
    "\n",
    "- numpy matrix operations (without training) \n",
    "- implement every matrix operation with a single PyTorch layer\n",
    "- implement the as a PyTorch model with training.\n",
    "\n",
    "Here a [good introduction to PyTorch](https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e) that covers more technical details than needed for this assignment. \n",
    "\n",
    "## Prediction Task:\n",
    "\n",
    "Given an example sentence $words$ such as\n",
    "\n",
    "```[\"Fall\",\"colors\", \"in\", \"New\", \"Hampshire \", \"are\", \"best\", \"seen\", \"right\", \"now\",\"!\"] ```\n",
    "\n",
    "the task is to mark selected words such as \"Hampshire hires\", here $Y$ is a sequence that for each word in $w\\in words$ marks whether the word is selected ($Y_w=1$) or not ($Y_w=0$).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Your Assignment\n",
    "\n",
    "\n",
    "You will be implementing the following convolutional neural network:\n",
    "\n",
    "(bottom to top)\n",
    "\n",
    "- X is the one-hot encoding of each word (provided)\n",
    "- Projection: $X \\rightarrow_{\\Theta} E$\n",
    "- Convolution $E \\rightarrow_{\\text{conv }W} H$\n",
    "- Detection $H \\rightarrow_{\\Psi, \\text{ReLU}} D$\n",
    "- Prediction $Y \\rightarrow_{\\text{max pool}} Y$\n",
    "- words $i$ with $Y_i>0$ will be selected\n",
    "\n",
    "We will ignore the bias term for all of these layers. The model is a variant on CNNs, in that the detector layer has an additional linear component $\\Psi$\n",
    ".\n",
    "\n",
    "See section \"Network Setup\" for sizes of convolution windows etc.\n",
    "\n",
    "\n",
    "### Part 1: Prediction with given parameters using Numpy/Einsum\n",
    "\n",
    "You are given parameters for both examples under (\"Fixed Parameters.. \") and some settings for embedding dimension and convolutional window (\"Network settings\")\n",
    "\n",
    "Your task is to emulate the CNN using Numpy's matrix operations and non-linear activations, to predict which words are selected.\n",
    "\n",
    "Please give results for both examples (we provide reference results for one example)\n",
    "\n",
    "\n",
    "### Part 2: Layer-by-Layer in PyTorch\n",
    "\n",
    "Using the parameters from Part 1, your task is to implement every layer of the network using an indiviual PyTorch layer object.  (No training yet!)\n",
    "\n",
    "You will use one of the inputs generated from Part 1, the parameter used in Part 1, to produce an output with a PyTorch layer. Then you will verify whether the output matches your resut from Part 1.\n",
    "\n",
    "\n",
    "\n",
    "### Part 3: Training and Prediction with PyTorch\n",
    "\n",
    "Now we add the layers from Part 1 to an Neural network and train it \"end-to-end\" (e.g. $X \\rightarrow Y$).\n",
    "\n",
    "Here we will be replace the one-hot encoding with pre-trained word embedding. (Setup code for word embedding below under \"Pre-trained Word embeddings\")\n",
    "\n",
    "\n",
    "### Part 4: Replace One-hot Encoding with Pre-trained Word Embeddings\n",
    "\n",
    "We provide stub code to download and use pre-trained word embeddings like word2vec or GloVE.\n",
    "\n",
    "All you have to do is to change the inputs to use the embedding vectors in your model.\n",
    "\n",
    "(If your project involves NLP, you probably want to do that anyway)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup and PyTorch Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# uncomment one of these versions (depending on whether you are on a computer with a CPU or not)\n",
    "\n",
    "# GPU version\n",
    "#!conda install --yes --prefix {sys.prefix} pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "\n",
    "# Just CPU\n",
    "#!conda install --yes --prefix {sys.prefix} pytorch torchvision cpuonly -c pytorch\n",
    "\n",
    "\n",
    "\n",
    "# install `Einops` for einstein-style tensor manipulation in pytorch\n",
    "# Also see https://github.com/arogozhnikov/einops\n",
    "#!conda install --yes --prefix {sys.prefix} einops  -c conda-forge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0176, 0.0416, 0.3021],\n",
      "        [0.7034, 0.1340, 0.6787],\n",
      "        [0.8742, 0.8389, 0.0737],\n",
      "        [0.6353, 0.2256, 0.0679],\n",
      "        [0.8472, 0.1184, 0.3079]])\n",
      "GPU/CUDA available?  False\n",
      "Torch version 1.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brendanjcrowe/anaconda3/envs/seq/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# torch test\n",
    "\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "\n",
    "print(\"GPU/CUDA available? \", torch.cuda.is_available())\n",
    "\n",
    "\n",
    "print(\"Torch version\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "flavor=\"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper print function for numpy matrices of dtype float\n",
    "\n",
    "def pretty(matrix):\n",
    "    return np.round(matrix,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Input Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Fall', 0.0),\n",
       " ('colors', 0.0),\n",
       " ('in', 0.0),\n",
       " ('New', 1.0),\n",
       " ('Hampshire ', 1.0),\n",
       " ('are', 0.0),\n",
       " ('best', 0.0),\n",
       " ('seen', 0.0),\n",
       " ('right', 0.0),\n",
       " ('now', 0.0),\n",
       " ('!', 0.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"Fall\",\"colors\", \"in\", \"New\", \"Hampshire \", \"are\", \"best\", \"seen\", \"right\", \"now\",\"!\"]\n",
    "Y_star=np.array([0,0,0,1,1,0,0,0,0,0,0], dtype=float)\n",
    "\n",
    "list(zip(words,Y_star))  # print (word, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Setup\n",
    "\n",
    "Hyperparameters and a set of example parameters you will be using throughout the exercise\n",
    "\n",
    "(For layers in the network see \"Your Assignment\" above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setup of inputs and dimensions of hidden layers / convolution window / channels\n",
    "\n",
    "maxw = len(words) # length of input sequence  (could also be characters)\n",
    "\n",
    "vocab_dim = 11 # length of one-hot encoding\n",
    "# this will be overwritten we construct the vocabulary\n",
    "# alternatively set it to the dimension of your pre-trained word embedding\n",
    "\n",
    "embed_dim = 3 # project 1-hot into a 3D space\n",
    "\n",
    "conv_dim = 3  # convolution window of input around t: [t-conv_dim+1: t+1]\n",
    "\n",
    "conv_channels = 2 # number of output channels from convolution\n",
    "\n",
    "pooling_window = 1  # pooling window of t: [t-pooling_window : t+pooling_window] \n",
    "# is supposed to mean: pooling_window-many before and pooling_window-many after\n",
    "# note this is not how pytorch defines it, you will need to transform it appropriately\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed Parameters for Example\n",
    "\n",
    "I just created random parameters with the code below. These parameters will not lead to the optimal result, they are just here so you can verify each of your layers.\n",
    "\n",
    "I documented the dimensions for each parameter (and verified it in code). Please document your parts of the code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta dimension check: True (11, 3)\n",
      "W dimension check: True (3, 3, 2)\n",
      "Psi dimension check: True (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Embedding parameter: vocab_dim x embed_dim\n",
    "Theta=np.array(\n",
    "    [\n",
    "        [0.14, 0.23, 0.19],\n",
    "        [0.25, 0.7 , 0.54],\n",
    "        [0.8 , 0.46, 0.92],\n",
    "        [0.45, 0.53, 0.81],\n",
    "        [0.83, 0.04, 0.12],\n",
    "        [0.32, 0.88, 0.99],\n",
    "        [0.89, 0.67, 0.64],\n",
    "        [0.22, 0.33, 0.56],\n",
    "        [0.25, 0.3 , 0.3 ],\n",
    "        [0.44, 0.18, 0.97],\n",
    "        [0.7 , 0.87, 0.9 ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Theta dimension check:\", Theta.shape == (vocab_dim, embed_dim), Theta.shape)\n",
    "\n",
    "# convolution filter:  embed_dim x conv_dim x conv_channels\n",
    "W=np.array([[[0.03668675,1], [0.5651157,1] , [1.94466826,1]],\n",
    "            [[0.03668675,0.03], [0.5651157,0.56] , [1.94466826, 1.94]],\n",
    "            [[0.03668675,-0.3], [0.5651157,-1] , [1.94466826,-2]]])\n",
    "\n",
    "print(\"W dimension check:\", W.shape == (embed_dim, conv_dim, conv_channels), W.shape)\n",
    "\n",
    "\n",
    "# detector parameter: 1 x conv_channels \n",
    "Psi=np.array([[ 0.43,-0.3 ]])\n",
    "print(\"Psi dimension check:\", Psi.shape == (1, conv_channels) ,Psi.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Implement with Matrix Operations\n",
    "\n",
    "In this section, implement the neural net using only regular matrix operators.\n",
    "\n",
    "You can use \n",
    "\n",
    "- Numpy or \n",
    "- low level pytorch data structure [tensors](https://pytorch.org/docs/stable/tensors.html) or [torch.einsum](https://pytorch.org/docs/stable/generated/torch.einsum.html) --- [explanation of einsum](https://stackoverflow.com/questions/55894693/understanding-pytorch-einsum)\n",
    "- or the Einstein Sum package [einops](https://github.com/arogozhnikov/einops) which works across numpy, pytorch, and tensorflow.\n",
    "\n",
    "\n",
    "Please document and check your dimensions. The assignment becomes a lot harder if you disregard this advice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs & Setup: $words \\rightarrow_{\\text{one hot}} X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the design matrix for words using one-hot encoding\n",
    "\n",
    "# 1. use an orderd dict to assign unique words to consecutive indexs\n",
    "# 2. generate a 1-hot encoding for each word\n",
    "# 3. compose the design matrix X by loading the encoding of each word\n",
    "# dimension of X = wmax x vocab_dim\n",
    "\n",
    "# at the end of the assignment, you will replace this with vectors from a pre-trained word embedding.\n",
    "\n",
    "from collections import OrderedDict \n",
    "dictionary = OrderedDict.fromkeys(words)\n",
    "dictionary = {w: idx for idx, w in enumerate (dictionary.keys())}  # Step 1\n",
    "\n",
    "vocab_dim = len(dictionary)\n",
    "\n",
    "dictionary_one_hot = np.eye(vocab_dim, dtype=float) # Step 2\n",
    "\n",
    "X = dictionary_one_hot[ [dictionary[w] for w in words] ] # Step 3\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection (Embedding): $X \\rightarrow_\\theta E$\n",
    "\n",
    "I recommend to first get it right for one word t=5, then create the tensor for all words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32, 0.88, 0.99])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# == Your Code! === \n",
    "\n",
    "# Parameter theta: vocab_dim x embed_dim\n",
    "# Input X : maxw x vocab_dim\n",
    "# Output E = maxw x embed_dim\n",
    "\n",
    "def projection(theta, X):\n",
    "    \n",
    "    return np.einsum('ij, jk -> ik', X, theta)\n",
    "\n",
    "\n",
    "E = projection(Theta, X)\n",
    "E[5]\n",
    "# Partial Reference result\n",
    "# E[5] = [0.3200, 0.8800, 0.9900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution:  $E \\rightarrow_{\\text{conv } W} H$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you need an integer division, this might be useful\n",
    "\n",
    "import math\n",
    "\n",
    "# integer ceil/floor\n",
    "math.floor(7/2), math.ceil(7/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.55219344, 1.5278    ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# == Your Code! === \n",
    "\n",
    "# Input E: maxw x embed_dim\n",
    "# Parameter W: embed_dim x conv_dim x conv_channels\n",
    "# Hyperparameter: conv_dim \n",
    "# Output H: maxw x conv_channels\n",
    "\n",
    "def convolution(W, E, conv_dim):\n",
    "    \n",
    "    pad = np.zeros((math.floor(conv_dim/2), E.shape[1]))\n",
    "    padE = np.vstack((pad, E, pad))\n",
    "\n",
    "    return np.array(\n",
    "        [\n",
    "            np.einsum(\n",
    "                'ji, ijk -> k',\n",
    "                padE[i:conv_dim+i],\n",
    "                W\n",
    "            )\n",
    "            for i in range(0, E.shape[0])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "H = convolution(W, E, conv_dim)\n",
    "H[5]\n",
    "# Partial Reference result\n",
    "# H[5] = array([5.55219344, 1.5278  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector: $H \\rightarrow_\\psi D$ with ReLU\n",
    "\n",
    "See discussion on [fastest way to implement ReLU in numpy](https://stackoverflow.com/questions/32109319/how-to-implement-the-relu-function-in-numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.92910318])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# == Your Code! === \n",
    "\n",
    "# Input H: maxw x conv_channels\n",
    "# Parameter Psi: 1 x conv_channels\n",
    "# Output D: maxw x 1\n",
    "\n",
    "def ReLU(H, psi):\n",
    "    \n",
    "    x = np.einsum('ij, kj -> i', H, psi)\n",
    "    \n",
    "    return (x * (x > 0)).reshape(-1, 1)\n",
    "\n",
    "\n",
    "D = ReLU(H, Psi)\n",
    "D[5]\n",
    "# Partial Reference Result\n",
    "# D[5] = 1.9291\n",
    "\n",
    "# I realize that my Psi parameter will not produce results below 0, hence ReLU does not filter. \n",
    "# Question for you, which Psi would be able to produce a result below 0?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I realize that my Psi parameter will not produce results below 0, hence ReLU does not filter. \n",
    "\n",
    "Question for you, which Psi would be able to produce a result below 0?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7868205 ],\n",
       "       [ 4.92474378],\n",
       "       [ 4.34837167],\n",
       "       [-0.        ],\n",
       "       [ 0.87395731],\n",
       "       [-0.        ],\n",
       "       [ 1.82298029],\n",
       "       [-0.        ],\n",
       "       [ 7.49669317],\n",
       "       [ 4.4226483 ],\n",
       "       [-0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your Psi, your code again\n",
    "\n",
    "psi = np.array([[1,-4]])\n",
    "\n",
    "d = ReLU(H, psi)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Pooling: $D \\rightarrow Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9291031781249997"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# == Your Code! === \n",
    "\n",
    "# Input D: maxw x 1 \n",
    "# Parameter pooling_window: 1\n",
    "# Output Y: maxw, \n",
    "\n",
    "def max_pool(pooling_window, D):\n",
    "    \n",
    "    pad = np.full((pooling_window, 1), np.min(D))\n",
    "    dPad = np.vstack((pad, D, pad))\n",
    "    return np.array(\n",
    "        [\n",
    "            np.max(dPad[i-pooling_window:i+pooling_window])\n",
    "            for i in range(1, D.shape[0]+1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "Y = max_pool(pooling_window, D)\n",
    "Y[5]\n",
    "# Partial reference result\n",
    "# Y[5] = 1.9291031781249997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Selection and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected words \n",
      " ['colors' 'in' 'New' 'now' '!']\n"
     ]
    }
   ],
   "source": [
    "# use the predicted Y variable to tell us which words were selected\n",
    "\n",
    "# replace Y with the variable name of your prediction\n",
    "\n",
    "words_array = np.array(words, dtype=object)\n",
    "\n",
    "print(\"selected words \\n\",words_array[Y>2]) \n",
    "\n",
    "\n",
    "# Reference result\n",
    "# selected words   ['colors' 'in' 'New' 'now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y [1.2  2.18 2.18 2.02 1.8  1.93 1.93 1.37 1.84 2.37 2.37]\n",
      "Y_star [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "MSE for ground truth y_star 3.3238344662803327\n"
     ]
    }
   ],
   "source": [
    "# Measure Mean-squared-Error to a ground truth\n",
    "\n",
    "print('Y',pretty(Y))\n",
    "print('Y_star', Y_star)\n",
    "\n",
    "mse=np.mean( (Y-Y_star)**2)\n",
    "print(\"MSE for ground truth y_star\", mse)\n",
    "\n",
    "\n",
    "# Reference result\n",
    "# MSE for ground truth y_star 2.683622245712982"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "... well, that is not a great result. But, hey, what did you expect from random parameters!?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# $\\star\\star\\star$ Now Everything in PyTorch  $\\star\\star\\star$\n",
    "\n",
    "[Tutorial using PyTorch for Convolutional Nets](https://www.tutorialspoint.com/pytorch/pytorch_convolutional_neural_network.htm)\n",
    "\n",
    "[Cheat Sheet of PyTorch utilities](https://www.analyticsvidhya.com/blog/2019/09/introduction-to-pytorch-from-scratch/?utm_source=blog&utm_medium=building-image-classification-models-cnn-pytorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops.layers.torch import Rearrange, Reduce # Maybe you are brave and are going to use these..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Conv1d\n",
    "\n",
    "My suggestion is to first understand the **convolution operation**:\n",
    "\n",
    "- [nn.functional.conv1d](https://pytorch.org/docs/stable/nn.functional.html#conv1d)(inputs, filters)\n",
    "\n",
    "Let's first create a new toy example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filters\n",
      " tensor([[[-1.,  0.,  1.],\n",
      "         [ 0.,  1.,  2.]]])\n",
      "inputs\n",
      " tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
      "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3]), torch.Size([1, 2, 10]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches=1; batch=0\n",
    "seqlen=10\n",
    "inchannels=2\n",
    "outchannels=1\n",
    "# with a filter of conv_dim 3, the shrunk_seqlen=8\n",
    "\n",
    "filters = torch.ones(num_batches,inchannels,conv_dim)\n",
    "filters[None][:][:]=torch.arange(-1,2)\n",
    "filters[0][1]= filters[0][0]+1\n",
    "                     \n",
    "inputs = torch.ones(num_batches,inchannels,seqlen)\n",
    "inputs[None][:][:]=torch.arange(1,11)\n",
    "\n",
    "print(\"filters\\n\",pretty(filters))\n",
    "print(\"inputs\\n\",pretty(inputs))\n",
    "\n",
    "filters.shape, inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10., 13., 16., 19., 22., 25., 28., 31.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code using nn.functional.conv1d (no padding)\n",
    "\n",
    "C = nn.functional.conv1d(inputs, filters, padding=(0,))\n",
    "C\n",
    "#Reference result:\n",
    "#    [[[10., 13., 16., 19., 22., 25., 28., 31.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [1., 2., 3.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].T[0:3].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then implement first and second example of previous result with a **matrix operation**. I used [torch.einsum](https://pytorch.org/docs/stable/generated/torch.einsum.html) because I find it easier to use than transposed dot products -- you can use dot products if this works better for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.]), tensor([13.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code  implementing the same with einsum for the first and second example\n",
    "\n",
    "first = torch.einsum('ijk,jk->i', filters, inputs[0].T[0:3].T)\n",
    "second = torch.einsum('ijk,jk->i', filters, inputs[0].T[1:4].T)\n",
    "\n",
    "first, second\n",
    "# Reference result 10, 13\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use a **convolution layer** \n",
    "\n",
    "*if you are confused about layers, first work through the next section then return here*\n",
    "\n",
    "The input to Conv1d is a 3-ax tensor of $num\\_batches \\times inchannels \\times seqlen$. \n",
    "\n",
    "- Num\\_batches = 1, when we don't use minibatches.\n",
    "- Inchannels will be the dimensionality of the embedding of your input.\n",
    "- Seqlen ($L$) is the number of words (or characters)\n",
    "\n",
    "Use a layer without bias and with padding=2\n",
    "\n",
    "The output will be $num\\_batches \\times outchannels \\times shrunk\\_seqlen$\n",
    "\n",
    "- Num\\_batches is same as input\n",
    "- Outchannel is a hyperparameter for you to set, it will be the dimensionality resulting from a matrix product of your filter $W$ and one input entry (of dimensionality $inchannel$). In this example we can set it to 1.\n",
    "- Shrunk\\_seqlen ($L_{out}$) is roughly seqlen, but the convolution will chop off entries at the boundary, unless you compensate with padding. See [pytorch doc section \"shape\"](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html) for details.\n",
    "\n",
    "\n",
    "The parameter will be a tensor of shape $outchannels \\times inchannels \\times conv\\_dim$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  3.,   7.,  10.,  13.,  16.,  19.,  22.,  25.,  28.,  31.,   1.,\n",
       "          -10.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code using nn.Conv1d\n",
    "\n",
    "conv = nn.Conv1d(2, 1, 3, padding=2, padding_mode='zeros', bias=False)\n",
    "conv.weight.data = filters\n",
    "out = conv(inputs)\n",
    "out\n",
    "# Reference Result (you see two new elements on either end)\n",
    "#[[[  3.,   7.,  10.,  13.,  16.,  19.,  22.,  25.,  28.,  31.,   1., -10.]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I highly recommend the you create your own examples with different windows, channels, etc in a new notebook cell to make sure you understand how the convolution behaves. \n",
    "\n",
    "You may also want to think ahead about how to cut the left-over padding out of the output. If you do it wrong, your results will be shifted and you get some nasty off-by-one errors in your network. (Maybe max pooling was only invented because folks never got the cut-out right.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Each Layer on its Own\n",
    "\n",
    "next we look at each layer on its own, to make sure we got the in/out dimensions right\n",
    "\n",
    "Look at the pytorch documentation for more info:\n",
    "\n",
    "- [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)(in_features: int, out_features: int, bias: bool = True)  -- param: out_features x in_features\n",
    "- [nn.Conv1d](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)(in_channels: int, out_channels: int, Union[T, Tuple[T]], padding: Union[T, Tuple[T]] = 0, ....')\n",
    "- [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)()\n",
    "- [nn.MaxPool1d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html)(kernel_size:int, padding: int, ....)\n",
    "\n",
    "- composing neural layers with [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
    "\n",
    "Whenever you apply the layer to a tensor `$layer(tensor)` the function `apply` is called in [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert inputs and example parameters to torch tensors\n",
    "\n",
    "X_torch = torch.unsqueeze(torch.tensor(X, dtype=torch.float), 0)\n",
    "Theta_torch = torch.tensor(Theta, dtype=torch.float)\n",
    "W_torch = torch.tensor(W, dtype=torch.float)\n",
    "Psi_torch = torch.tensor(Psi, dtype=torch.float)\n",
    "\n",
    "X_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E [[0.14 0.23 0.19]\n",
      " [0.25 0.7  0.54]\n",
      " [0.8  0.46 0.92]\n",
      " [0.45 0.53 0.81]\n",
      " [0.83 0.04 0.12]\n",
      " [0.32 0.88 0.99]\n",
      " [0.89 0.67 0.64]\n",
      " [0.22 0.33 0.56]\n",
      " [0.25 0.3  0.3 ]\n",
      " [0.44 0.18 0.97]\n",
      " [0.7  0.87 0.9 ]] \n",
      "H [[ 3.2140205   0.6068    ]\n",
      " [ 5.10194378  0.0443    ]\n",
      " [ 4.76757167  0.1048    ]\n",
      " [ 3.0167558   1.1422    ]\n",
      " [ 4.88395731  1.0025    ]\n",
      " [ 5.55219344  1.5278    ]\n",
      " [ 3.48218029  0.4148    ]\n",
      " [ 2.3609573   0.7949    ]\n",
      " [ 3.61309317 -0.9709    ]\n",
      " [ 5.7330483   0.3276    ]\n",
      " [ 1.45416771  0.4416    ]] \n",
      "D [[1.19998881]\n",
      " [2.18054583]\n",
      " [2.01861582]\n",
      " [0.95454499]\n",
      " [1.79935165]\n",
      " [1.92910318]\n",
      " [1.37289753]\n",
      " [0.77674164]\n",
      " [1.84490006]\n",
      " [2.36693077]\n",
      " [0.49281212]] \n",
      "Y [1.19998881 2.18054583 2.18054583 2.01861582 1.79935165 1.92910318\n",
      " 1.92910318 1.37289753 1.84490006 2.36693077 2.36693077]\n"
     ]
    }
   ],
   "source": [
    "# We will not implement each layer on its own, using results from part 1 as inputs/outputs\n",
    "\n",
    "# We want to obtain the same outputs as above\n",
    "\n",
    "print(\"\\nE\",E,\"\\nH\", H,\"\\nD\",D,\"\\nY\",Y)\n",
    "\n",
    "\n",
    "# let's first convert our numpy results from part 1 to torch tensors\n",
    "# if you implemented Part 1 using pytorch tensors, a conversion is not necessary (you will get some warnings)\n",
    "\n",
    "### I am converting these tensors to the expectect size of the output of each layer\n",
    "H_torch = torch.einsum('ijk->ikj', torch.unsqueeze(torch.tensor(H, dtype=torch.float), 0))\n",
    "E_torch = torch.unsqueeze(torch.tensor(E, dtype=torch.float), 0)\n",
    "D_torch = torch.einsum('ijk->ikj', torch.unsqueeze(torch.tensor(D, dtype=torch.float), 0))\n",
    "\n",
    "Y_torch = torch.unsqueeze(torch.unsqueeze(torch.tensor(Y, dtype=torch.float), 0), 0)\n",
    "Y_star_torch = torch.unsqueeze(torch.unsqueeze(torch.tensor(Y_star, dtype=torch.float), 0), 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification helper using torch's MSE\n",
    "\n",
    "def verify(predicted, expected, detail=False):\n",
    "    \"\"\"Verify that expected dimensions match and the entries in tensor are sufficiently close\"\"\"\n",
    "    if detail:\n",
    "           print(\"predicted \\n\",predicted, \"\\n expected \\n\", expected)\n",
    "    if (not (predicted.size() == expected.size())):\n",
    "        print (\"Verify: Shapes don't match. Predicted \",predicted.size(), \"Expected\", expected.size())\n",
    "        return -1\n",
    "    else :\n",
    "        diff = (predicted.detach()-expected)**2\n",
    "        if detail: \n",
    "            print(\"diff \\n\", diff)\n",
    "        mse = torch.mean(diff)\n",
    "        return mse.item()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Your Layer-by-Layer Implementation\n",
    "\n",
    "Now we are reimplementing each layer of the network using torch's layers that we wire to\n",
    "\n",
    "- inputs (data or from previous layer)\n",
    "- parameters (the ones given above), set with `$layer.weight.data`\n",
    "- outputs\n",
    "\n",
    "then we verify that the outputs are the same as earlier.\n",
    "\n",
    "\n",
    "I give you example code for the first layer.\n",
    "\n",
    "**You will implement** the remaining layers, and verify that they are correct.\n",
    "\n",
    "With your implementation:\n",
    "\n",
    "- indicate the expected dimensions of your inputs, outputs, and parameter \n",
    "- take note how your input needs to be rotated/transposed to fit (I recommend [torch.einsum](https://pytorch.org/docs/stable/generated/torch.einsum.html) )\n",
    "- verify that you obtain the expected result  (if applicable: describe the issue in a comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First layer: Embedding  X --theta--> E\n",
    "\n",
    "no bias, use rearranged `Theta_torch` as parameter, output `E_out`\n",
    "\n",
    "(given as an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example First layer:  X --theta--> E\n",
    "\n",
    "# Inputs X: seq x vocab_dim\n",
    "# Output E: seq x embed_dim\n",
    "# Theta: vocab_dim x embed_dim\n",
    "# but param of this layer needs to be: embed_dim x vocab_dim\n",
    "\n",
    "\n",
    "# init the layer\n",
    "layer=nn.Linear(vocab_dim, embed_dim, bias=False)\n",
    "\n",
    "# convert Theta and set the layers' parameter\n",
    "layer.weight.data=torch.einsum('ve->ev',Theta_torch) # v: vocab, e: embedding\n",
    "\n",
    "# produce outputs of the layer\n",
    "E_out=layer(X_torch)\n",
    "\n",
    "\n",
    "# verify that we obtain the same results as before\n",
    "verify(E_out, E_torch )\n",
    "\n",
    "# 0.0 is perfect! (close to 0 is also okay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second layer: Convolution: E  --W--> H\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the **convolution layer** (if you are confused about layers, first work through the next section then return here):\n",
    "\n",
    "Use window of length `conv_dim`, with output channeld `conv_channels`, no bias, padding=1 \n",
    "\n",
    "\n",
    "The input to Conv1d is a 3-ax tensor of $num\\_batches \\times inchannels \\times seqlen$. \n",
    "\n",
    "- Num\\_batches = 1, when we don't use minibatches.\n",
    "- Inchannels will be the dimensionality of the embedding of your input.\n",
    "- Seqlen ($L$) is the number of words (or characters)\n",
    "\n",
    "\n",
    "The output will be $num\\_batches \\times outchannels \\times shrunk\\_seqlen$\n",
    "\n",
    "- Num\\_batches is same as input\n",
    "- Outchannel is a hyperparameter for you to set, it will be the dimensionality resulting from a matrix product of your filter $W$ and one input entry (of dimensionality $inchannel$). In this example we can set it to 1.\n",
    "- Shrunk\\_seqlen ($L_{out}$) is roughly seqlen, but the convolution will chop off entries at the boundary, unless you compensate with padding. See [pytorch doc section \"shape\"](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html) for details.\n",
    "\n",
    "\n",
    "The parameter will be a tensor of shape $outchannels \\times inchannels \\times conv\\_dim$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_out tensor([[[ 3.2140,  5.1019,  4.7676,  3.0168,  4.8840,  5.5522,  3.4822,\n",
      "           2.3610,  3.6131,  5.7330,  1.4542],\n",
      "         [ 0.6068,  0.0443,  0.1048,  1.1422,  1.0025,  1.5278,  0.4148,\n",
      "           0.7949, -0.9709,  0.3276,  0.4416]]], grad_fn=<SqueezeBackward1>) torch.Size([1, 2, 11])\n",
      "predicted \n",
      " tensor([[[ 3.2140,  5.1019,  4.7676,  3.0168,  4.8840,  5.5522,  3.4822,\n",
      "           2.3610,  3.6131,  5.7330,  1.4542],\n",
      "         [ 0.6068,  0.0443,  0.1048,  1.1422,  1.0025,  1.5278,  0.4148,\n",
      "           0.7949, -0.9709,  0.3276,  0.4416]]], grad_fn=<SqueezeBackward1>) \n",
      " expected \n",
      " tensor([[[ 3.2140,  5.1019,  4.7676,  3.0168,  4.8840,  5.5522,  3.4822,\n",
      "           2.3610,  3.6131,  5.7330,  1.4542],\n",
      "         [ 0.6068,  0.0443,  0.1048,  1.1422,  1.0025,  1.5278,  0.4148,\n",
      "           0.7949, -0.9709,  0.3276,  0.4416]]])\n",
      "diff \n",
      " tensor([[[5.6843e-14, 0.0000e+00, 2.2737e-13, 5.6843e-14, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6843e-14, 0.0000e+00,\n",
      "          1.4211e-14],\n",
      "         [3.5527e-15, 1.6792e-15, 2.2204e-16, 0.0000e+00, 0.0000e+00,\n",
      "          1.4211e-14, 3.5527e-15, 3.5527e-15, 1.4211e-14, 0.0000e+00,\n",
      "          8.8818e-16]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.063564027770734e-14"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional layer\n",
    "\n",
    "# Input E_out: maxw x embed_dim\n",
    "# Parameter W_torch: embed_dim x conv_dim x conv_channels\n",
    "# Hyperparameter: conv_dim \n",
    "# Output H: maxw x conv_channels\n",
    "\n",
    "conv = nn.Conv1d(in_channels=embed_dim, out_channels=conv_channels, kernel_size=conv_dim, padding=1, padding_mode='zeros', bias=False)\n",
    "conv.weight.data = torch.einsum('edc->ced', W_torch)\n",
    "H_out = conv(torch.einsum('bsi->bis', E_out))\n",
    "\n",
    " \n",
    "\n",
    "print('H_out', H_out, H_out.size())\n",
    "verify(H_out, H_torch, True ) # verify with previous result. This should return a scalar close to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 1])\n",
      "torch.Size([1, 11, 1])\n",
      "torch.Size([1, 1, 12])\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(\n",
    "        in_features=conv_channels,\n",
    "        out_features=1,\n",
    "        bias=False\n",
    "    )\n",
    "linear.weight.data = Psi_torch\n",
    "out = linear(torch.einsum('ijk->ikj', H_out))\n",
    "print(out.shape)\n",
    "relu = nn.ReLU()\n",
    "out = relu(out)\n",
    "print(out.shape)\n",
    "out = torch.einsum('ijk->ikj', out)\n",
    "max_pool = nn.MaxPool1d(pooling_window+1, padding=1, stride=1)\n",
    "out = max_pool(out)\n",
    "print(out.shape)\n",
    "#[1.2000, 2.1805, 2.1805, 2.0186, 1.7994, 1.9291, 1.9291, 1.3729, 1.8449,   2.3669, 2.3669])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Layer: Detector H---Psi-->D  with ReLU\n",
    "\n",
    "No bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted \n",
      " tensor([[[1.2000, 2.1805, 2.0186, 0.9545, 1.7994, 1.9291, 1.3729, 0.7767,\n",
      "          1.8449, 2.3669, 0.4928]]], grad_fn=<ReluBackward0>) \n",
      " expected \n",
      " tensor([[[1.2000, 2.1805, 2.0186, 0.9545, 1.7994, 1.9291, 1.3729, 0.7767,\n",
      "          1.8449, 2.3669, 0.4928]]])\n",
      "diff \n",
      " tensor([[[0.0000e+00, 5.6843e-14, 5.6843e-14, 3.5527e-15, 0.0000e+00,\n",
      "          1.4211e-14, 1.4211e-14, 3.5527e-15, 5.6843e-14, 5.6843e-14,\n",
      "          3.5527e-15]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4223048426027377e-14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your job\n",
    "\n",
    "# Input H: maxw x conv_channels\n",
    "# Parameter Psi: 1 x conv_channels\n",
    "# Output D: maxw x 1\n",
    "\n",
    "relu = nn.ReLU()\n",
    "D_out = relu(torch.einsum('bil,oi->bol', H_out, Psi_torch))\n",
    "\n",
    "verify(D_out, D_torch, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read off predictions D--maxpool--> Y\n",
    "\n",
    "Use a pooling window of length `pooling_window`, but the MaxPool1d parameters is defined differently from my definition (see comment in definition of `pooling_window` above)\n",
    "\n",
    "use stride=1, output variable `Y_out`\n",
    "\n",
    "Use appropriate padding and cut out the result to get a single prediction for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted \n",
      " tensor([[[1.2000, 2.1805, 2.1805, 2.0186, 1.7994, 1.9291, 1.9291, 1.3729,\n",
      "          1.8449, 2.3669, 2.3669]]], grad_fn=<ViewBackward>) \n",
      " expected \n",
      " tensor([[[1.2000, 2.1805, 2.1805, 2.0186, 1.7994, 1.9291, 1.9291, 1.3729,\n",
      "          1.8449, 2.3669, 2.3669]]])\n",
      "diff \n",
      " tensor([[[0.0000e+00, 5.6843e-14, 5.6843e-14, 5.6843e-14, 0.0000e+00,\n",
      "          1.4211e-14, 1.4211e-14, 1.4211e-14, 5.6843e-14, 5.6843e-14,\n",
      "          5.6843e-14]]])\n",
      "3.488118946242888e-14\n",
      "predicted \n",
      " tensor([[[1.2000, 2.1805, 2.1805, 2.0186, 1.7994, 1.9291, 1.9291, 1.3729,\n",
      "          1.8449, 2.3669, 2.3669]]], grad_fn=<ViewBackward>) \n",
      " expected \n",
      " tensor([[[0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]]])\n",
      "diff \n",
      " tensor([[[1.4400, 4.7548, 4.7548, 1.0376, 0.6390, 3.7214, 3.7214, 1.8848,\n",
      "          3.4037, 5.6024, 5.6024]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3238351345062256"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "# Input D: maxw x 1 \n",
    "# Parameter pooling_window: 1\n",
    "# Output Y: maxw, \n",
    "\n",
    "maxpool = nn.MaxPool1d(pooling_window+1, padding=1, stride=1)\n",
    "Y_out = torch.einsum('ijk->kji', torch.einsum('ijk->kji', maxpool(D_out))[:-1])\n",
    "\n",
    "print(verify(Y_out, Y_torch, True))\n",
    "verify(Y_out, Y_star_torch, True)\n",
    "#it might not perfectly match up because of the padding, below my reference result\n",
    "#[1.2000, 2.1805, 2.1805, 2.0186, 1.7994, 1.9291, 1.9291, 1.3729, 1.8449,   2.3669, 2.3669])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part 3: Full model\n",
    "\n",
    "Starting with a one-hot encoding, we could train our own embedding as part of the end-to-end network model. However, the length of the vectors will grow with the size of the vocabulary. Instead, we will use a pre-trained embedding called word2vec, that maps most word in the English language to a dense fixed length vector.  \n",
    "\n",
    "(Dense means, each vector has very few zeros, in contrast to a one-hot embedding, \n",
    "fixed length means that if we grow our vocabulary, the embedding vectors will still have the same length, such as 300)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Build a PyTorch model (use default initialization)\n",
    "\n",
    "Here an example code stub to follow.\n",
    "\n",
    "Please please please: instead of calling the layers `layer1` give them informative names.\n",
    "\n",
    "Don't forget to re-arrange the output tensors as inputs for the next layer.\n",
    "\n",
    "```python\n",
    "\n",
    "# I suggest following this code stub\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer1 = ...\n",
    "        self.layer2 = ....\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = einops.rearrange(out,'i j k-> j k i') # re-arrange the output tensor to match the input\n",
    "        out = self.layer2(out)\n",
    "        ...\n",
    "        out = out[:][0].narrow(1,1,out.shape[3]-1) # drop second dimension, then cut off last element from pooling with padding\n",
    "        return out\n",
    "\n",
    "model = MyModel()   \n",
    "```\n",
    "\n",
    "Alternatively you can use `nn.Sequence()` with a Rearrange layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your task!\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(\n",
    "#         in_features=vocab_dim,\n",
    "#         out_features=embed_dim,\n",
    "#         bias=False\n",
    "#     ),\n",
    "#     Rearrange(\n",
    "#         'i j k -> i k j'\n",
    "#     ),\n",
    "#     nn.Conv1d(\n",
    "#         in_channels=embed_dim,\n",
    "#         out_channels=conv_channels,\n",
    "#         kernel_size=conv_dim,\n",
    "#         padding=1,\n",
    "#         padding_mode='zeros',\n",
    "#         bias=False\n",
    "#     ),\n",
    "#     Rearrange(\n",
    "#         'i j k -> i k j'\n",
    "#     ),\n",
    "#     nn.Linear(\n",
    "#         in_features=conv_channels,\n",
    "#         out_features=1,\n",
    "#         bias=False\n",
    "#     ),\n",
    "#     Rearrange(\n",
    "#         'i j k -> i k j'\n",
    "#     ),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool1d(\n",
    "#         kernel_size=pooling_window,\n",
    "#         stride=1\n",
    "#     ),\n",
    "#     Reduce\n",
    "# )\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embed = nn.Linear(\n",
    "            in_features=vocab_dim,\n",
    "            out_features=embed_dim,\n",
    "            bias=False\n",
    "        )\n",
    "        self.convolve = nn.Conv1d(\n",
    "            in_channels=embed_dim,\n",
    "            out_channels=conv_channels,\n",
    "            kernel_size=conv_dim,\n",
    "            padding=1,\n",
    "            padding_mode='zeros',\n",
    "            bias=False\n",
    "        )\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=conv_channels,\n",
    "            out_features=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.detect = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(\n",
    "            kernel_size=pooling_window+1,\n",
    "            padding=1,\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        out = einops.rearrange(out,'i j k -> i k j') # re-arrange the output tensor to match the input\n",
    "        out = self.convolve(out)\n",
    "        out = einops.rearrange(out,'i j k -> i k j')\n",
    "        out = self.linear(out)\n",
    "        out = einops.rearrange(out,'i j k -> i k j')\n",
    "        out = self.detect(out)\n",
    "        out = self.pool(out)\n",
    "        out = einops.rearrange(einops.rearrange(out, 'i j k -> k j i')[:-1], 'i j k -> k j i')\n",
    "        #out = einops.rearrange(einops.rearrange(out, 'i j k -> k j i')[0:11], 'i j k -> k j i')\n",
    "        return out\n",
    "\n",
    "model = MyModel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers \n",
      " [MyModel(\n",
      "  (embed): Linear(in_features=11, out_features=3, bias=False)\n",
      "  (convolve): Conv1d(3, 2, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=False)\n",
      "  (detect): ReLU()\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "), Linear(in_features=11, out_features=3, bias=False), Conv1d(3, 2, kernel_size=(3,), stride=(1,), padding=(1,), bias=False), Linear(in_features=2, out_features=1, bias=False), ReLU(), MaxPool1d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)]\n",
      "\n",
      "Parameters \n",
      " [Parameter containing:\n",
      "tensor([[-0.2572, -0.1168,  0.2335, -0.0669,  0.0920, -0.0185, -0.0072, -0.2580,\n",
      "         -0.2038,  0.0268, -0.0545],\n",
      "        [ 0.1234,  0.1247, -0.2031,  0.1124, -0.2242,  0.0449, -0.2339, -0.1328,\n",
      "         -0.2193,  0.0307,  0.1619],\n",
      "        [-0.2972, -0.2047, -0.1752,  0.0485,  0.1938, -0.0009,  0.1328,  0.0664,\n",
      "          0.1533, -0.2809, -0.1320]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.1481,  0.2029,  0.2662],\n",
      "         [ 0.0964, -0.0884, -0.0966],\n",
      "         [ 0.0912, -0.3096, -0.1752]],\n",
      "\n",
      "        [[-0.2484,  0.0738,  0.2325],\n",
      "         [-0.0313, -0.1717,  0.0926],\n",
      "         [-0.2885,  0.2926, -0.2955]]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0061, -0.5964]], requires_grad=True)]\n",
      "\n",
      "Access parameters via their names \n",
      "\n",
      "embed.weight \n",
      " tensor([[-0.2572, -0.1168,  0.2335, -0.0669,  0.0920, -0.0185, -0.0072, -0.2580,\n",
      "         -0.2038,  0.0268, -0.0545],\n",
      "        [ 0.1234,  0.1247, -0.2031,  0.1124, -0.2242,  0.0449, -0.2339, -0.1328,\n",
      "         -0.2193,  0.0307,  0.1619],\n",
      "        [-0.2972, -0.2047, -0.1752,  0.0485,  0.1938, -0.0009,  0.1328,  0.0664,\n",
      "          0.1533, -0.2809, -0.1320]])\n",
      "convolve.weight \n",
      " tensor([[[ 0.1481,  0.2029,  0.2662],\n",
      "         [ 0.0964, -0.0884, -0.0966],\n",
      "         [ 0.0912, -0.3096, -0.1752]],\n",
      "\n",
      "        [[-0.2484,  0.0738,  0.2325],\n",
      "         [-0.0313, -0.1717,  0.0926],\n",
      "         [-0.2885,  0.2926, -0.2955]]])\n",
      "linear.weight \n",
      " tensor([[-0.0061, -0.5964]])\n"
     ]
    }
   ],
   "source": [
    "# get access to the internal state of your model\n",
    "\n",
    "layers=list(model.modules())\n",
    "print('layers \\n', layers)\n",
    "print()\n",
    "\n",
    "\n",
    "print('Parameters \\n', list(model.parameters()))\n",
    "\n",
    "print()\n",
    "print('Access parameters via their names \\n')\n",
    "for name, param in model.named_parameters():\n",
    "    print(name,'\\n', param.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_torch tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]) torch.Size([1, 11, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0489, 0.0489, 0.0000, 0.0406, 0.0406, 0.0857, 0.0857, 0.0718,\n",
       "          0.0718, 0.0181, 0.0181]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the parameters are set to some random-ish initialization.\n",
    "# Before we train it, let's produce some random predictions.\n",
    "\n",
    "# Forward pass: Compute predicted y by passing x to the model\n",
    "# If your X is called differently, just change the variable\n",
    "\n",
    "print(\"X_torch\",X_torch, X_torch.shape)\n",
    "\n",
    "y_pred = model(X_torch)\n",
    "y_pred.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be a good opportunity to familiarize yourself with `torch.utils.data.Dataset` and `TensorDataset`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code Stub\n",
    "\n",
    "construct a MSELoss function using the ground truth $Y^\\star$  (`Y_star`)\n",
    "\n",
    "If your variables are called differently, you may have to change them below.\n",
    "\n",
    "(code stub below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  0.17012378573417664\n",
      "epoch:  100  loss:  0.14087682962417603\n",
      "epoch:  200  loss:  0.10477027297019958\n",
      "epoch:  300  loss:  0.062069013714790344\n",
      "epoch:  400  loss:  0.02598913200199604\n"
     ]
    }
   ],
   "source": [
    "def train(xdata, ydata, model):\n",
    "    '''Train the neural model with the given training data'''\n",
    "\n",
    "    #Construct the loss function\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    # Construct the optimizer (Stochastic Gradient Descent in this case)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)  # lr is learning rate\n",
    "\n",
    "    # Gradient Descent\n",
    "    for epoch in range(500):\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        Y_pred = model(xdata)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(Y_pred, ydata)\n",
    "        if epoch % 100 == 0: print('epoch: ', epoch,' loss: ', loss.item()) \n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model\n",
    "        \n",
    "model = train(X_torch, Y_star_torch, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Y_pred (learned) \n",
      " tensor([[[0.0254, 0.0254, 0.0000, 0.8331, 0.8331, 0.0863, 0.0863, 0.0796,\n",
      "          0.0796, 0.0000, 0.0589]]])\n",
      "\n",
      " Y_star_torch (truth) \n",
      " tensor([[[0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]]])\n",
      "\n",
      " Y_torch (result of fixed params) \n",
      " tensor([[[1.2000, 2.1805, 2.1805, 2.0186, 1.7994, 1.9291, 1.9291, 1.3729,\n",
      "          1.8449, 2.3669, 2.3669]]])\n",
      "\n",
      " trained params \n",
      " [Parameter containing:\n",
      "tensor([[-0.2524, -0.1062,  0.5303, -0.1435, -0.1438, -0.0032, -0.0267, -0.2453,\n",
      "         -0.1774,  0.0172, -0.0517],\n",
      "        [ 0.1109,  0.1340, -0.2241,  0.3049, -0.3584,  0.0049, -0.1987, -0.1661,\n",
      "         -0.1942,  0.0314,  0.1559],\n",
      "        [-0.2824, -0.2255,  0.0032, -0.1869,  0.4837,  0.0449,  0.0407,  0.1044,\n",
      "          0.0976, -0.2842, -0.1261]], requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.1424,  0.2035,  0.2659],\n",
      "         [ 0.0981, -0.0915, -0.0934],\n",
      "         [ 0.0934, -0.3086, -0.1798]],\n",
      "\n",
      "        [[-0.5467,  0.1088,  0.2126],\n",
      "         [ 0.0612, -0.3350,  0.2650],\n",
      "         [-0.1649,  0.3414, -0.5370]]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0146, -0.9557]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# Print predictions after training finishes\n",
    "Y_pred = model(X_torch)\n",
    "print(\"\\n Y_pred (learned) \\n\", Y_pred.detach())\n",
    "print(\"\\n Y_star_torch (truth) \\n\", Y_star_torch.detach())\n",
    "print(\"\\n Y_torch (result of fixed params) \\n\", Y_torch.detach())\n",
    "print(\"\\n trained params \\n\",  list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference Result\n",
    "\n",
    "# [...]\n",
    "# epoch:  498  loss:  0.001912423176690936\n",
    "# epoch:  499  loss:  0.0019004556816071272\n",
    "# Y_pred (learned) tensor([0.0363, 0.0248, 0.0248, 0.0000, 0.9709, 0.9709, 0.1259, 0.0000, 0.0131,\n",
    "#         0.0179, 0.0179], grad_fn=<SliceBackward>)\n",
    "# Y_star_torch (truth) tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
    "# trained params [Parameter containing:\n",
    "# tensor([[ 3.3846e-02,  1.5053e-01,  5.3871e-02, -2.7892e-01,  4.4570e-02,\n",
    "#           2.3433e-01,  5.0296e-01, -2.8384e-01,  2.9082e-01,  4.3104e-02,\n",
    "#          -5.5689e-02],\n",
    "#         [ 1.8341e-01,  4.4496e-02,  6.9729e-02, -1.8623e-01,  5.0794e-01,\n",
    "#          -9.3826e-02, -6.1965e-01, -2.6323e-01,  1.2437e-01,  4.4976e-02,\n",
    "#          -6.0869e-02],\n",
    "#         [-5.7301e-04, -1.2836e-01,  1.8387e-01,  1.3956e-02,  2.2719e-01,\n",
    "#           7.8836e-02, -2.7487e-01,  2.9157e-01, -2.7401e-03, -2.8299e-01,\n",
    "#          -4.6545e-03]], requires_grad=True), Parameter containing:\n",
    "# tensor([[[ 0.0102, -0.1001,  0.2383],\n",
    "#          [ 0.0295, -0.1764, -0.1163],\n",
    "#          [ 0.1335,  0.1075, -0.2252]],\n",
    "\n",
    "#         [[ 0.0554,  0.2765,  0.5179],\n",
    "#          [ 0.5025, -0.2487, -0.6356],\n",
    "#          [-0.0068,  0.2304, -0.1850]]], requires_grad=True), Parameter containing:\n",
    "# tensor([[0.1969, 0.8541]], requires_grad=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, produce some predictions \n",
    "(here we are using the training sequence again, something you should of course never do...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected words \n",
      " ['New' 'Hampshire ']\n",
      "Y_pred tensor([[[0.0254, 0.0254, 0.0000, 0.8331, 0.8331, 0.0863, 0.0863, 0.0796,\n",
      "          0.0796, 0.0000, 0.0589]]], grad_fn=<ViewBackward>)\n",
      "Y_star [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "loss tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "MSE for ground truth y_star tensor(0.0080, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Which words were selected?\n",
    "\n",
    "\n",
    "Y_pred = model(X_torch)\n",
    "\n",
    "words_array = np.array(words, dtype=object)\n",
    "print(\"selected words \\n\",words_array[Y_pred[0][0]>0.5])\n",
    "\n",
    "print('Y_pred',Y_pred)\n",
    "print('Y_star', Y_star)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "print('loss', criterion(Y_pred, Y_star_torch))\n",
    "\n",
    "mse=torch.mean( (Y_pred.detach()-Y_star)**2)  # detach takes the tensor out of the network\n",
    "print(\"MSE for ground truth y_star\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference Results\n",
    "\n",
    "# selected words \n",
    "#  ['New' 'Hampshire ']\n",
    "# Y_pred tensor([0.0415, 0.0415, 0.0773, 0.7233, 0.7233, 0.1414, 0.1414, 0.0286, 0.0780,\n",
    "#         0.0780, 0.0000], grad_fn=<SliceBackward>)\n",
    "# Y_star [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
    "# loss tensor(0.0196, grad_fn=<MseLossBackward>)\n",
    "# MSE for ground truth y_star tensor(0.0196, dtype=torch.float64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Replace One-Hot-Encoding with Pre-trained Word embeddings\n",
    "\n",
    "\n",
    "We will follow a standard approach of first embedding all words with a pre-trained embedding, such as word2vec. Then using this as input for the network.\n",
    "\n",
    "Below some template code to lookup words in word2vec which yield a 300dim vector. To start with a smaller example, we downsample 300 into 10, but subdividing the 50-dim word vector into batches of 5 entries, and summing them.\n",
    "\n",
    "More info here word2vec with gensim:\n",
    "- [Gensim - Topic modelling for humans: word2vec](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html)\n",
    "- [Word Embedding: Word2Vec with Genism, NLTK, and t-SNE Visualization](https://medium.com/analytics-vidhya/word-embedding-word2vec-with-genism-nltk-and-t-sne-visualization-43eae8ab3e2e).\n",
    "\n",
    "\n",
    "We will be downloading a 50-dim GloVE embedding (because it does not take up much space).\n",
    "I recommend to save the model file locally once, then load it with \n",
    "\n",
    "You can also download alternatives models, call `gensim.downloader.api.info()` for a list.\n",
    "\n",
    "Below some code stub to access the word embeddings. All you have to do is to form a substitute for $X$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gensim, to use word2vec word embeddings\n",
    "\n",
    "# Install gensim (for pre-trained word embeddings)\n",
    "#!conda install --yes --prefix {sys.prefix} gensim \n",
    "\n",
    "\n",
    "# test:\n",
    "\n",
    "#import gensim\n",
    "\n",
    "# ONLY if you get an error after `import gensim`:\n",
    "#\n",
    "# update your smart_open liberary\n",
    "#!conda install --yes --prefix {sys.prefix} smart_open\n",
    "# restart your notebook\n",
    "# see if `import gensim` works now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader\n",
    "\n",
    "wv = gensim.downloader.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "# # lookup the word vector for a word \"king\"\n",
    "# wv['king']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding of `king` [ 0.49562895  1.1722751  -4.3306704   2.07816    -2.7060602   0.50451\n",
      "  0.68607   ]\n",
      "embedding of `a` [ 1.58374    -1.50257    -2.3603408   3.70191     0.25554505  0.21705\n",
      "  0.46515   ]\n",
      "embedding of `not a valid word` [0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# downsampled embedding and zero vector for unknown words\n",
    "# note the following code assums the the word embedding dimensions are dividible by 5\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def glove_embed(word:str, target_dim)->np.array:\n",
    "    '''\n",
    "        Looks up word in embedding (downsampled to five dimensions), pads with beginning of embedding.\n",
    "        Returns zero vector for unknown words.\n",
    "    '''\n",
    "    # these parameters work for 50-dim glove embeddings (adjust for other embeddings)\n",
    "    sampled_dim = 5\n",
    "    sample_batches = 10\n",
    "    \n",
    "    empty_vec=np.zeros(target_dim)\n",
    "    if word in wv:\n",
    "        w2v = wv[word] # lookup 50 dim vector\n",
    "        a=einops.reduce(w2v,'(d seg)-> d', \"sum\", seg=sample_batches)  # downsample\n",
    "        b=w2v[0:target_dim-sampled_dim]\n",
    "        return np.hstack([a,b])\n",
    "    else:\n",
    "        return empty_vec\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "print('embedding of `king`', glove_embed('king',7))\n",
    "print('embedding of `a`', glove_embed('a',7))\n",
    "print('embedding of `not a valid word`', glove_embed('not a valid word',7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=10\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.convolve = nn.Conv1d(\n",
    "            in_channels=embed_dim,\n",
    "            out_channels=conv_channels,\n",
    "            kernel_size=conv_dim,\n",
    "            padding=1,\n",
    "            padding_mode='zeros',\n",
    "            bias=False\n",
    "        )\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=conv_channels,\n",
    "            out_features=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.detect = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(\n",
    "            kernel_size=pooling_window+1,\n",
    "            padding=1,\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.convolve(x)\n",
    "        out = einops.rearrange(out,'i j k -> i k j')\n",
    "        out = self.linear(out)\n",
    "        out = einops.rearrange(out,'i j k -> i k j')\n",
    "        out = self.detect(out)\n",
    "        out = self.pool(out)\n",
    "        out = einops.rearrange(einops.rearrange(out, 'i j k -> k j i')[:-1], 'i j k -> k j i')\n",
    "\n",
    "        return out\n",
    "\n",
    "model = MyModel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  0.37963974475860596\n",
      "epoch:  100  loss:  0.015953142195940018\n",
      "epoch:  200  loss:  0.0031155706383287907\n",
      "epoch:  300  loss:  0.0005920543917454779\n",
      "epoch:  400  loss:  0.00010298789129592478\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "\n",
    "X2_torch = torch.einsum(\n",
    "    'ijk->ikj',\n",
    "    torch.unsqueeze(\n",
    "        torch.tensor(\n",
    "            np.array(\n",
    "                [\n",
    "                    glove_embed(word, embed_dim)\n",
    "                    for word in words\n",
    "                ]\n",
    "            ),\n",
    "            dtype=torch.float\n",
    "        ),\n",
    "        0\n",
    "    )\n",
    ")\n",
    "X2_torch \n",
    "\n",
    "def train(xdata, ydata, model):\n",
    "    '''Train the neural model with the given training data'''\n",
    "\n",
    "    #Construct the loss function\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    # Construct the optimizer (Stochastic Gradient Descent in this case)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)  # lr is learning rate\n",
    "\n",
    "    # Gradient Descent\n",
    "    for epoch in range(500):\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        Y_pred = model(xdata)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(Y_pred, ydata)\n",
    "        if epoch % 100 == 0: print('epoch: ', epoch,' loss: ', loss.item()) \n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model\n",
    "model = train(X2_torch, Y_star_torch, model)\n",
    "Y2 = model(X2_torch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected words \n",
      " ['New' 'Hampshire ']\n"
     ]
    }
   ],
   "source": [
    "words_array = np.array(words, dtype=object)\n",
    "\n",
    "print(\"selected words \\n\",words_array[Y2[0][0]>0.5]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are results changing when you use a the loss function [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the model is trained with a single sentence.\n",
    "How to extend the model to train from multiple sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you feel inclined I recommend to implement POS tagging example from the previous programming assignment in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  0.9274263978004456\n",
      "epoch:  100  loss:  0.4716719686985016\n",
      "epoch:  200  loss:  0.43585205078125\n",
      "epoch:  300  loss:  0.4091963469982147\n",
      "epoch:  400  loss:  0.3729363679885864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.0400, 0.0309, 0.0425, 0.8390, 0.7686, 0.0643, 0.0095, 0.0147, 0.0242,\n",
       "         0.0334, 0.1353], grad_fn=<SelectBackward>),\n",
       " tensor([0.9600, 0.9691, 0.9575, 0.1610, 0.2314, 0.9357, 0.9905, 0.9853, 0.9758,\n",
       "         0.9666, 0.8647], grad_fn=<SelectBackward>))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.convolve = nn.Conv1d(\n",
    "            in_channels=embed_dim,\n",
    "            out_channels=conv_channels,\n",
    "            kernel_size=conv_dim,\n",
    "            padding=1,\n",
    "            padding_mode='zeros',\n",
    "            bias=False\n",
    "        )\n",
    "        self.pool = nn.MaxPool1d(\n",
    "            kernel_size=pooling_window+1,\n",
    "            padding=1,\n",
    "            stride=1\n",
    "        )\n",
    "        self.detect = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.convolve(x)\n",
    "        out = self.pool(out)\n",
    "        out = einops.rearrange(einops.rearrange(out, 'i j k -> k j i')[:-1], 'k j i -> i k j')\n",
    "        out = self.detect(out)\n",
    "        out = torch.squeeze(out, 0)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = MyModel() \n",
    "\n",
    "X2_torch = torch.einsum(\n",
    "    'ijk->ikj',\n",
    "    torch.unsqueeze(\n",
    "        torch.tensor(\n",
    "            np.array(\n",
    "                [\n",
    "                    glove_embed(word, embed_dim)\n",
    "                    for word in words\n",
    "                ]\n",
    "            ),\n",
    "            dtype=torch.float\n",
    "        ),\n",
    "        0\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def train(xdata, ydata, model):\n",
    "    '''Train the neural model with the given training data'''\n",
    "\n",
    "    #Construct the loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # Construct the optimizer (Stochastic Gradient Descent in this case)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)  # lr is learning rate\n",
    "\n",
    "    # Gradient Descent\n",
    "    for epoch in range(500):\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        Y_pred = model(xdata)\n",
    "        \n",
    "        \n",
    "        # Compute and print loss\n",
    "        loss = criterion(Y_pred, torch.squeeze(ydata).long())\n",
    "        if epoch % 100 == 0: print('epoch: ', epoch,' loss: ', loss.item()) \n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model\n",
    "\n",
    "model = train(X2_torch, Y_star_torch, model)\n",
    "Y2 = model(X2_torch)\n",
    "Y2.T[1], Y2.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected words \n",
      " ['New' 'Hampshire ']\n"
     ]
    }
   ],
   "source": [
    "words_array = np.array(words, dtype=object)\n",
    "\n",
    "print(\"selected words \\n\",words_array[Y2.T[1]>0.5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above I created a new model to use cross-entropy. You cannot directly use the cross entropy loss on our prvious models, as the output only value for a single class but we have two. I started by simply adding a linear model that expanded out output to 2 demensions and then put that through a softmax activation to get probabilities for both classes. This did not work well as we are over contraining our problem, and the model gets stuck. I realized that mapping our results for the convolution to a single output was getting ride of important information in our new context, so i removed this layer. Next I sumrmized that the ReLU was redundent as we are using a softmax at the end as a detector, so i removed that too. Now our Pooling layer feeds directly into softmax which gives as a probability for each word for each class. This is now the output we desire and using the cross entropy we can detect the words correctly. The value for the loss is much worse than our other models, but I think that that is due to the cross entropy loss being less forgiving that MSE. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
